{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cs103 import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPSC 103 - Systematic Program Design\n",
    "# Module 07a Day 2 -- Supplemental\n",
    "Ian Mitchell, with thanks to Rik Blok, Jessica Wong and Giulia Toti\n",
    "\n",
    "Note that the discussion below is specific to 2024W1 offering.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reminders\n",
    "- Wed-Fri: Module 7 (HtDAP) tutorial.  Attendance will be taken.\n",
    "- Friday: Project milestone due.\n",
    "- next Monday: Module 8 (Visualization): Pre-lecture assignment.\n",
    "- next Monday: Module 5 (Arbitrary-Sized): Tutorial Resubmission.\n",
    "- next Wednesday: Complete [final exam conflict form](https://ubc.ca1.qualtrics.com/jfe/form/SV_3w0efA3WAvy1pMW) if you have a conflict with our final exam slot.\n",
    "\n",
    "See your Canvas calendar (https://canvas.ubc.ca/calendar) for details.\n",
    "\n",
    "### A Few Useful Things\n",
    "\n",
    "- **If you are feeling distressed or overwhelmed then reach out and talk to somebody!** UBC has extensive resources listed on the student health page https://students.ubc.ca/health.  Use them!\n",
    "- See [Piazza post @513](https://piazza.com/class/m0li3cza8an2th/post/513) for the full tutorial schedule for the rest of the term.  (Some but not all optional.)\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "### ⚠️ [Project Milestone](https://canvas.ubc.ca/courses/147818/assignments/1966018)\n",
    "   \n",
    "**DUE:** Friday Nov 22.\n",
    "\n",
    "You should already be working on it.\n",
    "- Watch for your [mentor assignment](https://canvas.ubc.ca/courses/147818/pages/project-mentor-assignments)\n",
    "- Get help:\n",
    "  - [Office hours](https://canvas.ubc.ca/courses/147818/pages/schedule-tutorials-and-office-hours).\n",
    "  - Optional tutorial sessions on Thursday Nov 14 and Friday Nov 15 (today and tomorrow).\n",
    "  - Optional lectures on Tuesday Nov 19 (next Tuesday).\n",
    "    \n",
    "You do not need to design `main` and `analyze` for the milestone.\n",
    "\n",
    "Review the [Project Milestone grading rubric](https://canvas.ubc.ca/courses/147818/assignments/1966018) carefully so that your submission fulfills our requirements!\n",
    "    \n",
    "**Syzygy may crash occasionally or become very slow as the deadline approaches, due to the volume of activity.  Be sure to start early.**\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "    \n",
    "### ⛔ Don't use built-in functions!\n",
    "    \n",
    "- For the project, you are **NOT** allowed to use built-in functions like `len`, `sum`, `min`, `max`, etc.\n",
    "- Demonstrate how you would use good programming practices to implement the correct code yourself; in other words, write helper function(s).\n",
    "    \n",
    "</div>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Design Analysis Programs (HtDAP)\n",
    "\n",
    "The steps in the HtDAP recipe are: \n",
    "1. Planning\n",
    "<ol style=\"list-style-type:lower-alpha\">\n",
    "    <li>Plan input: Identify the information in the file your program will read.</li>\n",
    "    <li>Plan output: Write a description of what your program will produce.</li>\n",
    "    <li>Plan examples: Write or draw examples of what your program will produce.</li>\n",
    "</ol>\n",
    "2. Designing the program\n",
    "<ol style=\"list-style-type:lower-alpha\">\n",
    "    <li>Design data definitions.</li>\n",
    "    <li>Design read function: Design a function to read the information and store it as data in your program.</li>\n",
    "    <li>Design analyze function: Design functions to analyze the data.</li>\n",
    "</ol>\n",
    "\n",
    "Already completed all of the planning steps and designed the data definitions.  See `module07a-day2` notebook for details.  We include the data definitions from that notebook in the cell below so that we can use them during step 2b.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slightly simpler than what we designed last week\n",
    "# (in alignment with our answer just above.\n",
    "\n",
    "from enum import Enum\n",
    "# Shorthand way of including multiple definitions (NamedTuple and List) from a single library (typing).\n",
    "from typing import NamedTuple, List\n",
    "\n",
    "##################\n",
    "# Data Definitions\n",
    "\n",
    "\n",
    "CrimeType = Enum('CrimeType', ['BEC', 'BER', 'TV', 'TB'])\n",
    "# interp. A type of crime in our file.  One of:\n",
    "#   Break-and-enter Commercial (BEC),\n",
    "#   Break-and-enter Residential (BER),\n",
    "#   Theft of vehicle (TV), or\n",
    "#   Theft of bicycle (TB).\n",
    "\n",
    "# examples redundant for enumeration\n",
    "\n",
    "# template based on Enumeration (4 cases)\n",
    "@typecheck\n",
    "def fn_for_crime_type(ct: CrimeType) -> ...:\n",
    "    if ct == BEC:\n",
    "        return ...\n",
    "    elif ct == BER:\n",
    "        return ...\n",
    "    elif ct == TV:\n",
    "        return ...\n",
    "    elif ct == TB:\n",
    "        return ...\n",
    "    \n",
    "CrimeData = NamedTuple('CrimeData', [('type', CrimeType),\n",
    "                                     ('hour', int)]) # in range [0,23]\n",
    "# interp. Information about a crime, including the type of crime and hour of the day\n",
    "# in the range [0,23] that the crime occurred\n",
    "\n",
    "CD0 = CrimeData(CrimeType.BEC, 0)\n",
    "CD1 = CrimeData(CrimeType.BER, 1)\n",
    "CD2 = CrimeData(CrimeType.TV, 13)\n",
    "CD3 = CrimeData(CrimeType.TB, 23)\n",
    "\n",
    "# template based on Compound (2 fields) and reference rule\n",
    "@typecheck\n",
    "def fn_for_crime_data(cd: CrimeData) -> ...:\n",
    "    return ...(fn_for_crime_type(cd.type), cd.hour)\n",
    "\n",
    "# List[CrimeData]\n",
    "# interp. a list of CrimeData\n",
    "\n",
    "LOCD0 = []\n",
    "LOCD1 = [CD0]\n",
    "LOCD2 = [CD0, CD1]\n",
    "LOCD3 = [CD0, CD1, CD2, CD3]\n",
    "\n",
    "# template based on Arbitrary-sized and reference rule\n",
    "@typecheck\n",
    "def fn_for_locd(locd: List[CrimeData]) -> ...:\n",
    "    # description of the accumulator\n",
    "    acc = ...      # type: ...\n",
    "    for cd in locd:\n",
    "        acc = ...(fn_for_crime_data(cd), acc)\n",
    "\n",
    "    return ...(acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2b: Design `read` function\n",
    "\n",
    "Design a function to read the information and store it as data in your program:\n",
    "- You should complete the `read` function from its template. \n",
    "- Change the `Consumed` type name.\n",
    "- Check what columns from the file you need.\n",
    "- Check if the types need *parsing*; in other words, changing the data representation from the type that was read into the type we will store as data.\n",
    "  - Remember: All values in the CSV file are represented as strings when they are read. \n",
    "- You can also add any other helper function you need (e.g. to remove rows with missing/invalid data).\n",
    "- You should create at least two small CSV files for testing, so you can be sure your function is working before using it on full datasets. \n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "⚠️ You may skip irrelevant columns and rows with missing/invalid data when reading.  But **don't remove any other rows** (for example, don't filter for a specific `CrimeType` here.)  That's part of the chosen analysis and should be handled later.  At this point we want to read **all** valid, relevant data.\n",
    "    \n",
    "</div>\n",
    "\n",
    "## Filtering rows while reading\n",
    "\n",
    "How do we know which rows to filter at this `read` stage, and which we should keep (even if they will be filtered later at the `analyze` phase)?  You should keep every row *unless it cannot be correctly represented in the data structure that you designed* (typically because of missing or invalid data).  We need to throw away the rows which cannot be correctly represented because otherwise we would be using incorrect data during the `analyze` phase.  Of course, an alternative to throwing away rows which cannot be correctly represented is to go back and modify your data structure so that it can correctly represent these rows.\n",
    "\n",
    "Consider this example: What if the information in a particular column of your file is usually an integer but is sometimes missing?  If you choose to represent that column's information with a field of type `int` in your definition of `Consumed`, then you cannot correctly represent rows which do not have an integer in that column.  You then have to choose between throwing away those rows at the `read` phase or modifying your data structure so that you can correctly represent them.  An example of the latter would be to go back and modify the data definition for `Consumed` so that the type of the field corresponding to this column is `Optional[int]`.  Which approach you choose usually depends on whether you will need those rows with missing information during the `analyze` phase.\n",
    "\n",
    "In contrast, consider the case where we are only going to analyze information from the rows in which that column has a value which is strictly positive.  While it might look appealing to throw away those rows which have a negative or zero value in that column during the `read` phase, you *should not*.  You can correctly represent those values (negative or zero) just fine with the specified field type -- whether that type is `int` or `Optional[int]`; in other words, regardless of the choice you made above -- so you should keep those rows during the `read` phase.  Then during `analyze` you will filter out the data instances with negative or zero values in this field.\n",
    "\n",
    "<details class=\"alert alert-info\"><summary style=\"cursor:pointer; display:list-item\">ℹ️ But wouldn't it be more efficient to filter while reading?</summary>\n",
    "\n",
    "You might object that if we filter a row during the `read` phase, then we don't have to use any memory to represent that row in our list of consumed data, and the `analyze` phase won't ever need to look at that data.  That is true: it is more efficient to filter early.  But remember the goal when designing programs: *design and implement for correctness.*  Optimize only after you have correctness, and only if absolutely necessary to do the job.  \n",
    "\n",
    "If you are reading a data set with *billions* of rows then you *might* need to optimize your reading and analysis code *if* you need your answers quickly.  But for the kind of data and analysis that you are likely to work on, optimization is not worth the effort to do by hand or risk it presents of introducing a bug.  (I will note that the computer can often do a better job of optimizing your code with much less risk of creating a bug, so it is generally a great idea to use automated optimizations *after* you confirm that your unoptimized code is correct.  But that is a story for more advanced courses.)\n",
    "\n",
    "</details>\n",
    "\n",
    "Why do we keep this data at the `read` phase even if we know we are going to throw it away later?  We want to give the `analyze` phase correct data for as much information from our file as possible.  Therefore, keep any row that can be *correctly* represented even if it might be thrown away later.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2b: Design `read` function - Example\n",
    "\n",
    "#### Space reserved for helper function(s)\n",
    "\n",
    "Continue on to the next cell to design `read`.  We'll come back here later when we need to design a helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design your helper function(s) here.\n",
    "\n",
    "# Helper that we designed last Thursday.\n",
    "@typecheck\n",
    "def parse_crime_type(s:str) -> CrimeType:\n",
    "    \"\"\"\n",
    "    Returns the string s as a CrimeType.\n",
    "    \n",
    "    Assumes s is one of the following:\n",
    "        \"Break and Enter Commercial\"\n",
    "        \"Break and Enter Residential/Other\"\n",
    "        \"Theft of Bicycle\"\n",
    "        \"Theft of Vehicle\"\n",
    "    \"\"\"\n",
    "    # return CrimeType.BEC # stub\n",
    "    # template from atomic non-distinct\n",
    "    # return ...(s)\n",
    "    if s == \"Break and Enter Commercial\":\n",
    "        return CrimeType.BEC\n",
    "    elif s == \"Break and Enter Residential/Other\":\n",
    "        return CrimeType.BER\n",
    "    elif s == \"Theft of Bicycle\":\n",
    "        return CrimeType.TB\n",
    "    elif s == \"Theft of Vehicle\":\n",
    "        return CrimeType.TV\n",
    "    \n",
    "    \n",
    "start_testing()\n",
    "\n",
    "expect(parse_crime_type(\"Break and Enter Commercial\"), CrimeType.BEC)\n",
    "expect(parse_crime_type(\"Break and Enter Residential/Other\"), CrimeType.BER)\n",
    "expect(parse_crime_type(\"Theft of Bicycle\"), CrimeType.TB)\n",
    "expect(parse_crime_type(\"Theft of Vehicle\"), CrimeType.TV)\n",
    "\n",
    "summary()\n",
    "\n",
    "# Helper that will check whether a row contains valid data.\n",
    "# Uncomment the lines below when you are ready to create the helper.\n",
    "#@typecheck\n",
    "#def ...\n",
    "\n",
    "\n",
    "#start_testing()\n",
    "\n",
    "#expect(..., ...)\n",
    "\n",
    "#summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details class=\"alert alert-info\"><summary style=\"cursor:pointer; display:list-item\">ℹ️ Sample solution (For later.  Don't peek if you want to learn 🙂)</summary>\n",
    "\n",
    "```python\n",
    "@typecheck\n",
    "def is_reliable(row_data: List[str]) -> bool:\n",
    "    \"\"\"\n",
    "    Returns True if none of the pertinent data in row_data is missing,\n",
    "    otherwise returns False.\n",
    "    \n",
    "    Missing data is indicated by a \"0\" in both items 4 and 5\n",
    "    of the list.\n",
    "    \n",
    "    ASSUMES: row_data is a full row of values.  Specifically, row_data[4]\n",
    "    and row_data[5] must exist.\n",
    "    \"\"\"\n",
    "    # return True # stub\n",
    "    \n",
    "    # no template used\n",
    "    return row_data[4] != \"0\" or row_data[5] != \"0\"\n",
    "\n",
    "\n",
    "start_testing()\n",
    "\n",
    "# Examples and tests for is_reliable\n",
    "expect(is_reliable([\"0\", \"0\", \"0\", \"0\", \"1\", \"0\"]), True)\n",
    "expect(is_reliable([\"0\", \"0\", \"0\", \"0\", \"0\", \"1\"]), True)\n",
    "expect(is_reliable([\"1\", \"1\", \"1\", \"1\", \"0\", \"0\"]), False)\n",
    "\n",
    "summary()\n",
    "```\n",
    "    \n",
    "</details>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Design a function to read the information and store it as data in your program\n",
    "\n",
    "Here is a partially designed `read` function from last Thursday, including some test cases.  Let's give it a try!\n",
    "\n",
    "BTW: We have created some example files (see the current directory) and defined examples containing the expected results in the appendix below.  When we need it we'll [jump down](#Appendix:-Parsed-test-data) to copy that example data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@typecheck\n",
    "def read(filename: str) -> List[CrimeData]:\n",
    "    \"\"\"    \n",
    "    reads information from the specified file and returns a list of CrimeData compound instances.\n",
    "\n",
    "    Assume that there is at least a header row.\n",
    "    \"\"\"\n",
    "    #return []  #stub\n",
    "    # Template from HtDAP\n",
    "    # locd contains the data that has been read in so far\n",
    "    locd = [] # type: List[CrimeData]\n",
    "\n",
    "    with open(filename) as csvfile:\n",
    "        \n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader) # skip header line\n",
    "\n",
    "        for row_data in reader:\n",
    "            cd = CrimeData(parse_crime_type(row_data[0]), parse_int(row_data[4]))\n",
    "            locd.append(cd)\n",
    "    \n",
    "    return locd\n",
    "\n",
    "\n",
    "start_testing()\n",
    "\n",
    "# Examples and tests for read.\n",
    "\n",
    "# Uses the test files in the current directory\n",
    "# and the test data in the appendix below.\n",
    "expect(read('testfile_empty.csv'), [])\n",
    "# Tests that rows with unreliable data are filtered.\n",
    "expect(read('testfile_all_missing.csv'), [])\n",
    "# Tests BER crime type plus whether a row with zero value for hour\n",
    "# but nonzero value for minute is *not* filtered.\n",
    "expect(read('testfile_all_ber.csv'), TEST_ALL_BER)\n",
    "# Tests BEC crime data plus whether a row with unreliable data is filtered.\n",
    "# Rather than use the examples defined below, we could also copy the values\n",
    "# directly into this cell.\n",
    "expect(read('testfile_all_bec.csv'), [CrimeData(CrimeType.BEC, 6),\n",
    "                                  CrimeData(CrimeType.BEC, 18)])\n",
    "# Two more tests to check the other values of the enumeration.\n",
    "# Copied the values in the first one, used the variable in the second\n",
    "# for no particular reason.\n",
    "expect(read('testfile_all_tb.csv'), [CrimeData(CrimeType.TB, 1),\n",
    "                                 CrimeData(CrimeType.TB, 23),\n",
    "                                 CrimeData(CrimeType.TB, 17)])\n",
    "expect(read('testfile_all_tv.csv'), TEST_ALL_TV)\n",
    "\n",
    "summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<details class=\"alert alert-info\"><summary style=\"cursor:pointer; display:list-item\">ℹ️ Sample solution (For later.  Don't peek if you want to learn 🙂)</summary>\n",
    "\n",
    "```python\n",
    "@typecheck\n",
    "def read(filename: str) -> List[CrimeData]:\n",
    "    \"\"\"    \n",
    "    Reads information from the specified file and returns a list \n",
    "    of crime data.\n",
    "    \n",
    "    Ignores lines where both the hour and the minute are zero.\n",
    "    \"\"\"\n",
    "    # return []  #stub\n",
    "    # Template from HtDAP\n",
    "    # locd contains the result so far\n",
    "    locd = [] # type: List[CrimeData]\n",
    "\n",
    "    with open(filename) as csvfile:\n",
    "        \n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader) # skip header line\n",
    "\n",
    "        for row_data in reader:\n",
    "            # you may not need to store all the strings in the \n",
    "            # current row, and you may need to convert some\n",
    "            # of the strings to other types\n",
    "            if is_reliable(row_data):\n",
    "                cd = CrimeData(parse_crime_type(row_data[0]), \n",
    "                               parse_int(row_data[4]))\n",
    "                locd.append(cd)\n",
    "    \n",
    "    return locd\n",
    "\n",
    "\n",
    "start_testing()\n",
    "\n",
    "# Examples and tests for read\n",
    "expect(read('testfile_empty.csv'), [])\n",
    "expect(read('testfile_all_missing.csv'), [])\n",
    "expect(read('testfile_all_bec.csv'), TEST_ALL_BEC)\n",
    "expect(read('testfile_all_ber.csv'), TEST_ALL_BER)\n",
    "\n",
    "summary()\n",
    "```\n",
    "    \n",
    "</details>\n",
    "\n",
    "<details class=\"alert alert-info\"><summary style=\"cursor:pointer; display:list-item\">ℹ️ Why are we filtering at the read phase in this example?</summary>\n",
    "\n",
    "Because we cannot correctly represent \"no reliable timestamp\" using the two fields (`type` and `hour`) in our `CrimeData` compound.  If we just stored the value `0` in the `hour` field, then it would be *incorrectly* interpreted later as a timestamp between midnight and 1am.  There are several possible solutions:\n",
    "- Discard any row that has no reliable timestamp.  That is suitable if we will never use the information in those rows.\n",
    "- Modify our definition of `CrimeData` so that we can correctly represent missing data.  Some possibilities:\n",
    "  - Change the type of `hour` to be `Optional[int]`, where the value `None` represents an unreliable timestamp.\n",
    "  - Add a field `minute` of type `int` to our `CrimeData` compound, and store the minute column as well.  Then the `analyze` function could check whether the data is reliable.\n",
    "  - Add another field `reliable` of type `bool` to our `CrimeData` compound and create appropriate parsing logic in `read` (and likely a helper) to set this field correctly when reading a row.  Then the `analyze` function could check whether the data is reliable *without* needing to know about the unusual encoding in the hour and minute columns that the file uses.\n",
    "\n",
    "Clearly we have chosen the first option in this case.  It is the easiest since we don't need the information in those rows.\n",
    "</details>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests\n",
    "\n",
    "Don't use the original CSV file to test your program.  Otherwise you have to know the expected output before you've finished designing the program.  (Isn't this what the program is for? 😉)\n",
    "\n",
    "Instead, create special test files that contain a subset of the data.  Choose the subsets so that:\n",
    "1. They cover a wide range of data,\n",
    "2. They cover special cases and edge cases,\n",
    "3. They deliberately include some missing/invalid data that you think the program should be able to handle,\n",
    "3. It's easy to determine what the expected output should be.\n",
    "\n",
    "Small files are fine!  You might also want one or two tests with larger subsets.\n",
    "\n",
    "Give the test files names that help you remember what they're testing.  Feel free to construct artificial data or sample from the original CSV file.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "   \n",
    "ℹ️ Don't forget to submit all your test files with your program!\n",
    "    \n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using real data for testing\n",
    "\n",
    "Another common source of examples / test cases (in addition to creating dummy data files) is to extract a few rows from your real data set into a test data set.\n",
    "\n",
    "There are a number of ways to perform that extraction.  Here is a procedure that you can do in Jupyter / Syzygy:\n",
    "1. Make a copy of your original data set file.  You will only modify the copy so that (a) you still have your original data set and (b) if something goes wrong, you can always start over.\n",
    "2. Rename that copy to make it clear it is a test data set; for example, `testfile_real_rows.csv`.\n",
    "3. Open the copy in Jupyter's editor: Right click the file and select \"Open with > editor\".\n",
    "4. Now you can delete rows by selecting the row(s) and pressing the backspace or delete keys.  Make sure that you delete entire rows. If you accidentally delete part of a row, delete the rest of it.\n",
    "5. Keep only a few of the rows.  For convenience that is often the first and/or last few rows.  Delete the rest.  Save the test file and close the editor.\n",
    "6. Reopen the test file in the CSV viewer, and then construct the correct output data from those rows by hand.  The effort required for that process will dictate how many rows you keep in your test data set.\n",
    "\n",
    "Just to be clear: You are not *required* to include a subset of the real data among your test cases.  But it is a good way to make sure that you haven't accidentally designed a `read` function which handles dummy data but not real data.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Done (?)\n",
    "\n",
    "Have we handled all of the possible weirdness in our data set, `read` and helper functions?\n",
    "\n",
    "Hint: What type does `parse_int` return?\n",
    "\n",
    "<details class=\"alert alert-info\"><summary style=\"cursor:pointer; display:list-item\">ℹ️ Sample solution (For later.  Don't peek if you want to learn 🙂)</summary>\n",
    "\n",
    "If the string loaded from column 4 of a row cannot be converted into an integer, then `parse_int` will return `None`.  What happens then?\n",
    "\n",
    "<details class=\"alert alert-info\"><summary style=\"cursor:pointer; display:list-item\">ℹ️ How do we fix that? (For later.  Don't peek if you want to learn 🙂)</summary>\n",
    "\n",
    "There are several potential approaches to resolving this issue, and the right one will depend on the data set and how you plan to interpret it.\n",
    "- If you are confident that every string loaded from column 4 of your data set will correctly convert into an integer, you could make that part of your assumptions.  (Which you then need to document.)\n",
    "- If you want to treat rows with a missing or invalid string in column 4 as bad or missing data, then you should write a helper to identify those rows and include that helper in your `read` function's logic, in the same way that you used `is_reliable`.  (What template would you use?)\n",
    "- If you want to treat rows with a missing or invalid string in column 4 as if they had a value of `0` for the `hour` field (it is not unusual for people to omit 0 values to make a table more readable), then you should write a helper to parse a `None` value into a `0` value. (What template would you use?) (How would this choice interact with your logic for `is_reliable`?)\n",
    "- If you want to treat rows with a missing or invalid string in column 4 as a different category of crimes from those with a numeric value in this column, then you should modify your definition of `CrimeData` to use something other than `Interval[int]` as the type for the `hour` field.  (What type(s) could you use?)\n",
    "\n",
    "</details>\n",
    "\n",
    "</details>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: Parsed test data\n",
    "\n",
    "Here are the test files parsed into `List[CrimeData]`.  I've included this info here so we can quickly add it as needed to our examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from 'testfile_all_bec.csv'\n",
    "TEST_ALL_BEC = [CrimeData(CrimeType.BEC, 6),\n",
    "                CrimeData(CrimeType.BEC, 18)] # missing data removed\n",
    "\n",
    "# from 'testfile_all_ber.csv'\n",
    "TEST_ALL_BER = [CrimeData(CrimeType.BER, 21),\n",
    "                CrimeData(CrimeType.BER, 17),\n",
    "                CrimeData(CrimeType.BER, 0)] # reliable because nonzero minute field\n",
    "\n",
    "# from 'testfile_all_tb.csv'\n",
    "TEST_ALL_TB = [CrimeData(CrimeType.TB, 1),\n",
    "               CrimeData(CrimeType.TB, 23),\n",
    "               CrimeData(CrimeType.TB, 17)]\n",
    "\n",
    "# from 'testfile_all_tv.csv'\n",
    "TEST_ALL_TV = [CrimeData(CrimeType.TV, 23),\n",
    "               CrimeData(CrimeType.TV, 14),\n",
    "               CrimeData(CrimeType.TV, 21)]\n",
    "\n",
    "# from 'testfile_all_missing.csv'.\n",
    "# (But none of these rows should have been kept because\n",
    "#  the minute column in each row was also 0, indicating\n",
    "#  an unreliable timestamp.)\n",
    "TEST_ALL_MISSING = [CrimeData(CrimeType.BEC, 0),\n",
    "                    CrimeData(CrimeType.BER, 0),\n",
    "                    CrimeData(CrimeType.TB, 0),\n",
    "                    CrimeData(CrimeType.TV, 0)]\n",
    "\n",
    "# from 'testfile_empty.csv'\n",
    "TEST_EMPTY = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll run the cell here to create these instances and/or copy the data to help prepare [our examples above](#Step-2b:-Design-read-function---Example).\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
